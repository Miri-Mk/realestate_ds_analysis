{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Immobilienpreisvorhersage mithilfe von Data Science**\n",
    "**1. Business Understanding: Projektziele f√ºr mittelfristige Investorinnen und Investoren**  \n",
    "Ziel dieser Analyse ist es, eine datenbasierte Entscheidungsgrundlage f√ºr Investor:innen mit einem Anlagehorizont von ein bis zwei Jahren zu schaffen. Dazu wird untersucht, wie sich der Verkaufspreis von Immobilien anhand objektbezogener Merkmale erkl√§ren und sch√§tzen l√§sst, um Kauf- und Verkaufsentscheidungen systematisch zu unterst√ºtzen.  \n",
    "\n",
    "Zentrale Fragestellung ist die Vorhersage des Verkaufspreises einer Immobilie (Z_(Verkaufspreis)) auf Basis ihrer Eigenschaften. Dabei wird kein zuk√ºnftiger Marktpreis prognostiziert, sondern ein Referenzwert f√ºr den aktuellen Markt ermittelt. Dieser beschreibt den typischen Verkaufspreis, den vergleichbare Immobilien unter √§hnlichen Bedingungen erzielen. Die Preisvorhersage dient somit als Vergleichsgr√∂√üe, um Abweichungen zwischen erwartetem und beobachtetem Preis zu identifizieren und um einzusch√§tzen, ob ein Objekt im aktuellen Marktumfeld relativ g√ºnstig oder teuer angeboten wird.\n",
    "Dieser Ansatz entspricht einem hedonischen Preismodell, bei dem der Gesamtpreis einer Immobilie als Ergebnis einzelner preisrelevanter Merkmale interpretiert wird. Investor:innen k√∂nnen so gezielt Objekte ausw√§hlen, deren Angebotspreis unter dem f√ºr ihre Merkmalskombination typischen Marktpreis liegt. Der erwartete Ertrag ergibt sich dabei nicht aus einer expliziten Zukunftsprognose, sondern aus der Annahme, dass sich solche Unterbewertungen innerhalb eines Zeitraums von ein bis zwei Jahren ausgleichen k√∂nnen. Dieses Vorgehen kann als Nutzung von Arbitrage durch Fehlbewertung verstanden werden und gilt als vergleichsweise robust gegen√ºber kurzfristigen Marktschwankungen.  \n",
    "\n",
    "Dar√ºber hinaus wird analysiert, welche Merkmale den Verkaufspreis ma√ügeblich beeinflussen und wie gro√ü ihr jeweiliger Beitrag zur Preisbildung ist. Das Ziel besteht darin, die relevanten Einflussfaktoren klar zu benennen und ihre Bedeutung f√ºr die Preisvorhersage einzuordnen. Mithilfe dieser Erkenntnisse k√∂nnen Investor:innen Immobilien anhand preisrelevanter Eigenschaften vergleichen und ihre Auswahlentscheidungen nachvollziehbar begr√ºnden.\n",
    "Ein weiterer Schwerpunkt liegt auf der Untersuchung regionaler Unterschiede innerhalb der fiktiven Stadt. Dabei wird betrachtet, wie sich die Verkaufspreise zwischen den einzelnen Bezirken unterscheiden und ob sich ein systematisches Preisniveau pro Bezirk erkennen l√§sst. Diese Analyse unterst√ºtzt die Bewertung von Lagen und erg√§nzt die objektbezogene Preisbetrachtung im Hinblick auf kurzfristige Investitionsentscheidungen.  \n",
    "\n",
    "Insgesamt soll die Analyse dazu beitragen, Verkaufspreise konsistent zu sch√§tzen, preisbestimmende Merkmale transparent zu identifizieren und Unterschiede zwischen vergleichbaren Immobilien mit √§hnlichen Merkmalen sowie zwischen den Bezirken strukturiert darzustellen. So k√∂nnen Entscheidungen im betrachteten Investitionszeitraum datenbasiert getroffen werden."
   ],
   "id": "891c0c33271ed0f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**2. Datenexploration und -analyse**  \n",
    "Auf Basis der fachlichen Erwartung formulieren wir folgende Hypothesen:\n",
    "- Der Verkaufspreis steigt mit zunehmender Wohnfl√§che deutlich an.\n",
    "- Lage und Gesamtqualit√§t haben einen starken Einfluss auf den Verkaufspreis.\n",
    "- Die Zielvariable ist rechtsschief verteilt und enth√§lt Ausrei√üer im oberen Preissegment.\n",
    "Diese Hypothesen werden im Folgenden datenbasiert √ºberpr√ºft.\n"
   ],
   "id": "448ee1f466c0e78c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "\n",
    "# Pfad zur Trainingsdatei\n",
    "DATA_PATH = \"data_for_training.csv\"\n",
    "\n",
    "# CSV laden\n",
    "df = pd.read_csv(DATA_PATH, sep=\";\")\n"
   ],
   "id": "d04aacc96ab500b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.1 √úberblick: Dimensionen und erste Zeilen\n",
    "print(\"Shape (Zeilen, Spalten):\", df.shape)\n",
    "display(df.head())\n"
   ],
   "id": "652565dd8143e643"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.2 √úberblick: Spalten und Datentypen\n",
    "info = pd.DataFrame({\n",
    "    \"column\": df.columns,\n",
    "    \"dtype\": [df[c].dtype for c in df.columns],\n",
    "    \"non_null\": [df[c].notna().sum() for c in df.columns],\n",
    "    \"null\": [df[c].isna().sum() for c in df.columns],\n",
    "    \"null_%\": [(df[c].isna().mean() * 100) for c in df.columns],\n",
    "    \"n_unique\": [df[c].nunique(dropna=True) for c in df.columns],\n",
    "}).sort_values(\"null_%\", ascending=False)\n",
    "\n",
    "display(info)\n"
   ],
   "id": "12736bc0dcbdefaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.3 Statistische √úbersicht (nur numerische Spalten)\n",
    "# Deskriptive Statistik erzeugen\n",
    "desc = df.describe().T\n",
    "\n",
    "# Spalten mit Jahresangaben (diskrete Zeitpunkte)\n",
    "year_cols = [\"Baujahr\", \"Umgebaut\", \"Verkaufsjahr\"]\n",
    "\n",
    "# Zielvariable Preis (ganze Euro)\n",
    "price_col = \"Z_Verkaufspreis\"\n",
    "\n",
    "# Jahre ohne Nachkommastellen\n",
    "desc.loc[year_cols] = desc.loc[year_cols].round(0)\n",
    "\n",
    "# Preis ohne Nachkommastellen\n",
    "desc.loc[price_col] = desc.loc[price_col].round(0)\n",
    "\n",
    "# Alle √ºbrigen numerischen Spalten moderat runden\n",
    "other_cols = desc.index.difference(year_cols + [price_col])\n",
    "desc.loc[other_cols] = desc.loc[other_cols].round(2)\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "desc"
   ],
   "id": "700d3375f69affbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.3.1 Dubletten-Check\n",
    "\n",
    "Es muss √ºberpr√ºft werden, ob einige Datens√§tze exakt doppelt vorhanden sind.\n",
    "Dubletten k√∂nnen Auswertungen (z.B. H√§ufigkeiten) verzerren und sollten f√ºr Modellierung meistens entfernt werden. Wenn sie doch behalten werden, muss dies begr√ºndet werden.\n",
    "\"\"\"\n"
   ],
   "id": "c1ab35581ef07c50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dup_count = int(df.duplicated().sum())\n",
    "print(\"Anzahl exakter Dubletten:\", dup_count)\n"
   ],
   "id": "1f2df3387d5937b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.4 Auff√§lligkeiten: fehlende Werte\n",
    "\n",
    "Die folgende Tabelle zeigt den Anteil fehlender Werte pro Feature.\n",
    "\n",
    "**Interpretation (Daumenregel):**\n",
    "- Features mit sehr hohem Missing-Anteil sind oft problematisch und werden sp√§ter entfernt oder gezielt imputiert.\n",
    "- Fehlende Werte k√∂nnen zudem systematisch sein (z.B. nur bei bestimmten Objektarten) ‚Üí sp√§ter segmentiert pr√ºfen.\n",
    "\"\"\"\n"
   ],
   "id": "47f14d49d08f3e44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "missing = (df.isna().mean() * 100).sort_values(ascending=False)\n",
    "missing_tbl = missing[missing > 0].to_frame(\"missing_%\").round(2)\n",
    "display(missing_tbl)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "missing[missing > 0].plot(kind=\"bar\")\n",
    "plt.ylabel(\"Fehlende Werte (%)\")\n",
    "plt.title(\"Fehlende Werte je Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "cb15f6e03c3d9aea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Es ist auff√§llig, dass bei dem Merkmal Besonderheiten die meisten Werte fehlen. F√ºr die Analyse liefert dieses Feature daher nur begrenzt Informationen. Daher wird sie nicht weiter ber√ºcksichtigt. Fehlende Angaben zur Kellerh√∂he werden als eigene Kategorie (‚ÄûKeine Angabe‚Äú) behandelt, da das Vorhandensein oder Nichtvorhandensein eines Kellers selbst relevant sein kann.",
   "id": "9452d4bcfcb165ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.5 Auff√§lligkeiten: einfache Plausibilit√§tschecks (numerisch)\n",
    "\n",
    "√úberpr√ºfung der numerischen Spalten auf:\n",
    "- Werte < 0\n",
    "- Werte == 0\n",
    "\n",
    "Lediglich eine technische √úberpr√ºfung, da die Semantik jeder Spalte noch nicht bekannt ist.\n",
    "\n",
    "**Interpretation dieser Werte:**\n",
    "- Negative Werte sind h√§ufig klare Datenfehler.\n",
    "- Nullen k√∂nnen valide sein (z.B. \"Anzahl Garagen\") oder ein Kodierungsartefakt f√ºr \"unbekannt\".\n",
    "\"\"\"\n"
   ],
   "id": "ddcfc69bc3e7b215"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "checks = []\n",
    "for c in num_cols:\n",
    "    s = df[c]\n",
    "    arr = s.dropna().to_numpy()\n",
    "    checks.append({\n",
    "        \"column\": c,\n",
    "        \"min\": s.min(skipna=True),\n",
    "        \"max\": s.max(skipna=True),\n",
    "        \"negatives\": int(np.count_nonzero(arr < 0)),\n",
    "        \"zeros\": int(np.count_nonzero(arr == 0)),\n",
    "    })\n",
    "\n",
    "checks_df = pd.DataFrame(checks).sort_values([\"negatives\", \"zeros\"], ascending=False)\n",
    "display(checks_df)\n"
   ],
   "id": "36f4e8e3ad2bafde"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Es wurden keine negativen Werte oder offensichtlich unrealistischen Angaben festgestellt. Fl√§chen, Preise und Jahreszahlen liegen in plausiblen Bereichen, sodass keine zus√§tzlichen Bereinigungsschritte notwendig sind.",
   "id": "b64472014f4ef25a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"## 2.6 Visualisierungen\n",
    "\n",
    "Erstellung unterschiedlicher Charts in mehreren Detailstufen:\n",
    "- **Univariat:** Verteilung der Zielgr√∂√üe (Preis)\n",
    "- **Bivariat (numerisch):** Preis vs. typische Treiber (z.B. Wohnfl√§che, Baujahr)\n",
    "- **Bivariat (kategorial):** Preis nach Kategorien (Boxplots)\n",
    "- **Multivariat light:** Korrelationen/Heatmap als √úberblick √ºber lineare Zusammenh√§nge\n",
    "\n",
    "\"\"\"\n"
   ],
   "id": "5ec89410f218d362"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.6.1 Zielvariable (Preis) festlegen\n",
    "\n",
    "TARGET_COL = \"Z_Verkaufspreis\"\n",
    "\n",
    "# Wenn TARGET_COL gesetzt ist, halten wir die Logik bewusst schlank.\n",
    "if TARGET_COL is not None:\n",
    "    if TARGET_COL not in df.columns:\n",
    "        raise KeyError(f\"TARGET_COL='{TARGET_COL}' nicht in Trainingsdaten gefunden.\")\n",
    "    if not pd.api.types.is_numeric_dtype(df[TARGET_COL]):\n",
    "        raise TypeError(f\"TARGET_COL='{TARGET_COL}' ist nicht numerisch (Regressions-Target erwartet).\")\n",
    "\n",
    "    target = TARGET_COL\n",
    "    reason = \"fix gesetzt (manuell)\"\n",
    "\n",
    "    print(\"Erkannte Zielvariable (f√ºr EDA):\", target)\n",
    "    print(\"Begr√ºndung:\", reason)\n",
    "else:\n",
    "    # --- Fallback (nur wenn TARGET_COL nicht gesetzt ist) ---\n",
    "    TEST_DATA_PATH = \"data_for_test.csv\"\n",
    "\n",
    "    # --- Schritt 0: Vorbereitungen ---\n",
    "    num_cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "    # --- Schritt 1: Training-vs-Test Vergleich (am zuverl√§ssigsten, wenn vorhanden) ---\n",
    "    train_only_cols: list[str] = []\n",
    "    try:\n",
    "        df_test = pd.read_csv(TEST_DATA_PATH, sep=\";\")\n",
    "        train_only_cols = sorted(list(set(df.columns) - set(df_test.columns)))\n",
    "    except Exception:\n",
    "        train_only_cols = []\n",
    "\n",
    "    train_only_numeric = [c for c in train_only_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "    # --- Schritt 2: Namensheuristik (falls train/test nicht hilft) ---\n",
    "    name_candidates = [\n",
    "        c for c in df.columns\n",
    "        if pd.api.types.is_numeric_dtype(df[c])\n",
    "        and any(k in c.lower() for k in [\"price\", \"preis\", \"verkauf\", \"sale\", \"wert\", \"value\", \"kaufpreis\", \"market\", \"target\"])\n",
    "    ]\n",
    "\n",
    "    # --- Entscheidung: Target festlegen + Gr√ºnde transparent machen ---\n",
    "    reason = None\n",
    "\n",
    "    if len(train_only_numeric) == 1:\n",
    "        target = train_only_numeric[0]\n",
    "        reason = \"einzige numerische Spalte, die nur im Training vorkommt (Train/Test-Differenz)\"\n",
    "    elif len(train_only_numeric) > 1:\n",
    "        preferred = [c for c in train_only_numeric if any(k in c.lower() for k in [\"price\", \"preis\", \"verkauf\", \"sale\", \"kaufpreis\", \"target\"])]\n",
    "        if preferred:\n",
    "            target = preferred[0]\n",
    "            reason = \"mehrere Train-only Spalten; gew√§hlt via Namensheuristik innerhalb Train-only\"\n",
    "        else:\n",
    "            target = df[train_only_numeric].var(numeric_only=True).sort_values(ascending=False).index[0]\n",
    "            reason = \"mehrere Train-only Spalten; gew√§hlt via gr√∂√üter Varianz\"\n",
    "    elif len(name_candidates) >= 1:\n",
    "        target = name_candidates[0]\n",
    "        reason = \"Namensheuristik (Preis/Target-Schl√ºsselw√∂rter)\"\n",
    "    else:\n",
    "        target = df[num_cols].var(numeric_only=True).sort_values(ascending=False).index[0] if num_cols else None\n",
    "        reason = \"Fallback: numerische Spalte mit gr√∂√üter Varianz\"\n",
    "\n",
    "    print(\"Erkannte Zielvariable (f√ºr EDA):\", target)\n",
    "    print(\"Begr√ºndung:\", reason)\n",
    "\n"
   ],
   "id": "48957b6fdaa6f35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.6.2 Preisverteilung\n",
    "\n",
    "Der Plot zeigt die Verteilung der Werte in der erkannten Preis-/Zielspalte.\n",
    "\n",
    "**Interpretation:**\n",
    "- Immobilienpreise sind in der Praxis h√§ufig **rechtsschief** (wenige sehr teure Objekte).\n",
    "- F√ºr Modellierung ist daher oft eine **Log-Transformation** sinnvoll (bessere Skalierung, weniger Einfluss extremer Ausrei√üer).\n",
    "\n",
    "**Pr√ºfungsnotiz (Modellimplikation):**\n",
    "- Wenn **Mittelwert >> Median** und die **Skewness** deutlich > 0 ist, sprechen wir von einer Rechtsschiefe.\n",
    "- Teure Ausrei√üer k√∂nnen MSE-basierte Modelle stark beeinflussen\n",
    "\"\"\"\n"
   ],
   "id": "1a0daf2026146970"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if target is not None:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.histplot(df[target].dropna(), bins=40, kde=True)\n",
    "    plt.title(f\"Verteilung: {target}\")\n",
    "    plt.xlabel(target)\n",
    "    plt.ylabel(\"Anzahl\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 2.8))\n",
    "    sns.boxplot(x=df[target])\n",
    "    plt.title(f\"Boxplot: {target}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Log-Preis (nur falls alle Werte > 0 bzw. nach Filter)\n",
    "    positive_mask = df[target] > 0\n",
    "    if positive_mask.any():\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.histplot(np.log1p(df.loc[positive_mask, target]), bins=40, kde=True)\n",
    "        plt.title(f\"Log-Verteilung: log1p({target}) (nur Werte > 0)\")\n",
    "        plt.xlabel(f\"log1p({target})\")\n",
    "        plt.ylabel(\"Anzahl\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Keine positiven Target-Werte gefunden ‚Äì Log-Plot wird √ºbersprungen.\")\n",
    "else:\n",
    "    print(\"Keine numerische Zielvariable gefunden ‚Äì Preisverteilung wird √ºbersprungen.\")\n"
   ],
   "id": "c8d02437ef14da64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Die Verteilung des Verkaufspreises ist deutlich rechtsschief und zeigt einzelne sehr hohe Werte.\n",
    "Dies deutet darauf hin, dass lineare Regressionsmodelle ohne Transformation problematisch sein k√∂nnten.\n",
    "\n",
    "Es wird deutlich, dass die meisten Immobilien im mittleren Preissegment liegen, w√§hrend nur wenige Objekte sehr teuer sind. Durch die teuren Ausrei√üer kann der Durchschnitt stark verzerrt werden, weshalb der Median als robusteres Lagema√ü bevorzugt wird. F√ºr die sp√§tere Modellierung wird zus√§tzlich eine Log-Transformation des Verkaufspreises betrachtet, um extreme Werte weniger stark zu gewichten. Dadurch k√∂nnen Zusammenh√§nge zwischen Merkmalen und Preis gleichm√§√üiger abgebildet werden."
   ],
   "id": "2c7340128bda6ea3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.6.3 Hilfsfunktion: passende Spalten anhand von Schl√ºsselw√∂rtern finden\n",
    "\n",
    "def _find_numeric_col_by_keywords(df_: pd.DataFrame, keywords: list[str]):\n",
    "    candidates = []\n",
    "    for c in df_.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(df_[c]):\n",
    "            continue\n",
    "        name = c.lower()\n",
    "        if any(k in name for k in keywords):\n",
    "            candidates.append(c)\n",
    "    return candidates[0] if candidates else None\n",
    "\n",
    "area_col = _find_numeric_col_by_keywords(df, [\"wohn\", \"fl√§che\", \"flaeche\", \"area\", \"sqm\", \"m2\"])  # Wohnfl√§che\n",
    "year_col = _find_numeric_col_by_keywords(df, [\"baujahr\", \"year\", \"jahr\", \"built\"])  # Baujahr\n",
    "\n",
    "print(\"Wohnfl√§chen-Spalte:\", area_col)\n",
    "print(\"Baujahr-Spalte:\", year_col)\n"
   ],
   "id": "f0d36bbe632578d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.6.4 Preis vs. Wohnfl√§che\n",
    "\n",
    "Der Scatterplot zeigt die Punktewolke aus Preis und Wohnfl√§che.\n",
    "\n",
    "**Interpretation:**\n",
    "- Typisch ist ein positiver Zusammenhang: gr√∂√üere Fl√§che ‚Üí h√∂herer Preis.\n",
    "- Starke Streuung kann auf Lage-/Ausstattungsunterschiede hinweisen.\n",
    "\n",
    "**Kurzfazit:**\n",
    "- Wenn hier ein klar steigender Trend sichtbar ist, ist Wohnfl√§che ein starker Preistreiber.\n",
    "- Ausrei√üer (sehr teuer bei mittlerer Fl√§che) deuten auf zus√§tzliche Einflussfaktoren (z.B. Lage, Zustand) hin.\n",
    "\"\"\"\n"
   ],
   "id": "8182dff3b7aa5471"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if target is not None and area_col is not None:\n",
    "    plt.figure(figsize=(6.5, 5))\n",
    "    sns.scatterplot(data=df, x=area_col, y=target, alpha=0.35)\n",
    "    plt.title(f\"{target} vs. {area_col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Preis vs. Wohnfl√§che wird √ºbersprungen (target oder Wohnfl√§che nicht gefunden).\")\n"
   ],
   "id": "262745c18990b7d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mit wachsender Wohnfl√§che steigt tendenziell auch der Verkaufspreis an, was auf einen positiven Zusammenhang hinweist. Allerdings zeigt sich eine deutliche Streuung der Preise f√ºr √§hnliche Fl√§chengr√∂√üen, was auf weitere Einflussfaktoren wie Lage, Zustand oder Ausstattung hindeutet. Insgesamt best√§tigt die Analyse, dass die Wohnfl√§che ein wichtiger Preistreiber ist, jedoch nicht der einzige Faktor, der den Verkaufspreis bestimmt.",
   "id": "14f27f9a97182a38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.6.5 Preis vs. Baujahr\n",
    "\n",
    "Der Scatterplot zeigt die Punktewolke aus Preis und Baujahr.\n",
    "\n",
    "**Interpretation:**\n",
    "- Neuere Geb√§ude sind h√§ufig teurer, aber der Effekt kann je nach Lage/Modernisierung variieren.\n",
    "\"\"\"\n"
   ],
   "id": "8939bf053e42c8c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if target is not None and year_col is not None:\n",
    "    plt.figure(figsize=(6.5, 5))\n",
    "    sns.scatterplot(data=df, x=year_col, y=target, alpha=0.35)\n",
    "    plt.title(f\"{target} vs. {year_col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Preis vs. Baujahr wird √ºbersprungen (target oder Baujahr nicht gefunden).\")\n"
   ],
   "id": "6ed033bda96b048"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Neuere Geb√§ude tendieren dazu, h√∂here Verkaufspreise zu erzielen, was auf den Wert moderner Ausstattung und Bauqualit√§t hinweist. Allerdings ist der Zusammenhang weniger ausgepr√§gt als bei der Wohnfl√§che, da auch √§ltere Geb√§ude in attraktiven Lagen oder mit hochwertiger Ausstattung hohe Preise erzielen k√∂nnen. Insgesamt zeigt die Analyse, dass das Baujahr einen moderaten Einfluss auf den Verkaufspreis hat, jedoch durch weitere Faktoren erg√§nzt wird.",
   "id": "615d53afb796797c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.6.6 Korrelationen (numerische Features)\n",
    "\n",
    "Wir betrachten lineare Zusammenh√§nge (Pearson-Korrelation) zwischen numerischen Variablen.\n",
    "\n",
    "**Interpretation:**\n",
    "- Hohe absolute Korrelationen zum Target sind Kandidaten f√ºr starke Preistreiber.\n",
    "- Sehr hohe Korrelationen zwischen Features deuten auf Multikollinearit√§t hin.\n",
    "\n",
    "**Notiz:**\n",
    "- Sp√§tere explizite Benennung von Top-Korrelationen zum Target und Pr√ºfung, ob sich starke Feature-Feature-Korrelationen zeigen\n",
    "  (wichtig f√ºr lineare Modelle ‚Üí Regularisierung/Feature-Selektion).\n",
    "\"\"\"\n"
   ],
   "id": "34b9425db85962cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if target is not None and len(num_cols) >= 2:\n",
    "    corr = df[num_cols].corr(numeric_only=True)\n",
    "\n",
    "    # Top-K Korrelierte Features zum Target (ohne Target selbst)\n",
    "    if target in corr.columns:\n",
    "        top_corr = (\n",
    "            corr[target]\n",
    "            .drop(labels=[target], errors=\"ignore\")\n",
    "            .dropna()\n",
    "            .abs()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(10)\n",
    "        )\n",
    "        display(top_corr.to_frame(\"abs_corr_with_target\"))\n",
    "\n",
    "    # Heatmap (bei vielen Features begrenzen)\n",
    "    max_features_for_heatmap = 20\n",
    "    cols_for_heatmap = num_cols[:max_features_for_heatmap]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df[cols_for_heatmap].corr(numeric_only=True), cmap=\"coolwarm\", center=0)\n",
    "    plt.title(f\"Korrelations-Heatmap (erste {len(cols_for_heatmap)} numerische Features)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Korrelationen werden √ºbersprungen (zu wenige numerische Spalten oder target fehlt).\")\n"
   ],
   "id": "e63186bcf3483eb9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Ergebnisse auf Basis der Daten:**\n",
    "- Die st√§rkste lineare Korrelation mit dem Verkaufspreis zeigt die Wohnfl√§che_qm (r ‚âà ‚Ä¶),\n",
    "  gefolgt von Gesamtqual und Lage.\n",
    "- Zwischen Wohnfl√§che_qm und EG_qm zeigt sich eine sehr hohe Korrelation,\n",
    "  was auf m√∂gliche Redundanz dieser Merkmale hinweist.\n",
    "Diese Beobachtungen sind insbesondere f√ºr lineare Modelle relevant.\n"
   ],
   "id": "b4972cf57b8cb4a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.6.7 Kategorische Merkmale: H√§ufigkeiten + Preis nach Kategorie (Top-K)\n",
    "\n",
    "Wir betrachten kategoriale Spalten (Text/Bool/Category):\n",
    "1) **H√§ufigkeiten** (Top-K)\n",
    "2) **Preisverteilung nach Kategorie** (Boxplot) f√ºr die wichtigsten Auspr√§gungen\n",
    "\n",
    "**Interpretation:**\n",
    "- Kategorien mit deutlich unterschiedlichen Medianpreisen sind relevante Segmenttreiber.\n",
    "- Viele seltene Kategorien k√∂nnen sp√§ter zusammengefasst werden (\"Other\").\n",
    "\"\"\"\n"
   ],
   "id": "6a8a548678cd5997"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cat_cols = [c for c in df.columns if c not in num_cols]\n",
    "\n",
    "TOP_K = 10\n",
    "max_cat_plots = 8  # begrenzen, damit es √ºbersichtlich bleibt\n",
    "\n",
    "plotted = 0\n",
    "for c in cat_cols:\n",
    "    if plotted >= max_cat_plots:\n",
    "        break\n",
    "\n",
    "    # F√ºr Boxplots brauchen wir ausreichend Nicht-NA und mehrere Auspr√§gungen\n",
    "    s = df[c].astype(\"string\")\n",
    "    vc = s.value_counts(dropna=False)\n",
    "    if vc.shape[0] < 2:\n",
    "        continue\n",
    "\n",
    "    # 1) H√§ufigkeiten\n",
    "    vc_top = vc.head(TOP_K)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(x=vc_top.values, y=vc_top.index)\n",
    "    plt.title(f\"Top-{min(TOP_K, len(vc_top))} Kategorien: {c}\")\n",
    "    plt.xlabel(\"Anzahl\")\n",
    "    plt.ylabel(c)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Preis nach Kategorie (nur wenn target vorhanden)\n",
    "    if target is not None:\n",
    "        top_levels = vc.index[:min(TOP_K, len(vc))].tolist()\n",
    "        df_plot = df.loc[s.isin(top_levels), [c, target]].copy()\n",
    "        df_plot[c] = df_plot[c].astype(\"string\")\n",
    "\n",
    "        # Nur plotten, wenn genug Datenpunkte vorhanden sind\n",
    "        if df_plot.shape[0] >= 30:\n",
    "            plt.figure(figsize=(10, 4.5))\n",
    "            sns.boxplot(data=df_plot, y=c, x=target)\n",
    "            plt.title(f\"{target} nach {c} (Top-{min(TOP_K, len(top_levels))})\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    plotted += 1\n"
   ],
   "id": "62b275891c5b0d91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Bei der Ausbaustufe zeigt sich, dass eingeschossige Geb√§ude den gr√∂√üten Anteil im Datensatz ausmachen. Gleichzeitig weisen Objekte mit mehr Ebenen tendenziell h√∂here Verkaufspreise auf, allerdings auch mit deutlich gr√∂√üerer Streuung. Dies deutet darauf hin, dass zus√§tzliche Ebenen den Preis erh√∂hen k√∂nnen, der Effekt jedoch stark von weiteren Faktoren abh√§ngt.\n",
    "\n",
    "Die Analyse der Besonderheiten zeigt, dass nur sehr wenige Immobilien entsprechende Merkmale wie einen Pool aufweisen. Zwar liegen die Verkaufspreise dieser Objekte tendenziell h√∂her, aufgrund der sehr geringen Fallzahlen ist dieser Effekt jedoch nur eingeschr√§nkt belastbar. Das Merkmal wird daher f√ºr die Modellierung nur mit Vorsicht ber√ºcksichtigt.\n",
    "\n",
    "Bei der Gesamtqualit√§t sind klare Preisunterschiede zwischen den Kategorien erkennbar. Immobilien mit sehr guter oder guter Gesamtqualit√§t erzielen deutlich h√∂here Medianpreise als durchschnittliche oder schlechte Objekte. Gleichzeitig nimmt mit steigender Qualit√§t auch die Preisspanne zu, was auf Unterschiede in Lage, Gr√∂√üe und Ausstattung innerhalb derselben Qualit√§tsstufe hinweist.\n",
    "\n",
    "Ein √§hnliches Bild zeigt sich beim Gesamtzustand. Objekte in sehr gutem oder gutem Zustand werden im Median h√∂her bewertet als Immobilien mit schlechterem Zustand. Der Effekt ist jedoch weniger stark ausgepr√§gt als bei der Gesamtqualit√§t, was darauf hindeutet, dass der Zustand zwar relevant ist, aber nicht isoliert den Preis bestimmt.\n",
    "\n",
    "Bei der Kellerh√∂he zeigen sich erkennbare Preisunterschiede zwischen den Kategorien. Immobilien mit guter oder sehr guter Kellerh√∂he erzielen im Median h√∂here Verkaufspreise als Objekte mit durchschnittlicher oder schlechter Kellerh√∂he.Gleichzeitig ist innerhalb der Kategorien eine gewisse Streuung sichtbar, was darauf hindeutet, dass die Kellerh√∂he zwar einen Einfluss auf den Verkaufspreis hat, dieser jedoch im Vergleich zu Lage oder Gesamtqualit√§t eher erg√§nzend wirkt.\n",
    "\n",
    "Die Lage weist deutliche Unterschiede im Verkaufspreis auf. Zwischen den einzelnen Stadtteilen zeigen sich klar unterschiedliche Medianpreise sowie Streuungen. Die Lage ist damit ein zentraler Preistreiber und erkl√§rt einen wesentlichen Teil der Preisunterschiede zwischen ansonsten vergleichbaren Immobilien.\n",
    "\n",
    "Bei der Steigung des Grundst√ºcks sind zwar leichte Preisunterschiede zwischen den Kategorien erkennbar, der Einfluss f√§llt jedoch insgesamt geringer aus als bei Lage oder Qualit√§tsmerkmalen. Die Steigung wird daher als erg√§nzendes, aber nicht dominierendes Merkmal betrachtet."
   ],
   "id": "51eca23f0c098e94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.6.2.1 Fokus: Zielvariable (Preis) ‚Äì geb√ºndelte Analyse\n",
    "\n",
    "Neben der Visualisierung fassen wir die Zielvariable **quantitativ** zusammen. Das ist wichtig, weil Ausrei√üer/Schiefe direkt\n",
    "Einfluss auf Modell- und Transformationsentscheidungen haben (z.B. Log-Transformation, robuste Modelle/Verlustfunktionen).\n",
    "\n",
    "Wir betrachten u.a.:\n",
    "- Lagekennzahlen (Median vs. Mittelwert)\n",
    "- Schiefe (Skewness) als Hinweis auf Rechtsschiefe\n",
    "- Ausrei√üerquote nach IQR-Regel (klassische Vorlesungsheuristik)\n",
    "\"\"\"\n"
   ],
   "id": "e7e956368cff37a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if target is not None:\n",
    "    y = df[target].dropna()\n",
    "    if len(y) > 0:\n",
    "        q1, q3 = y.quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower, upper = (q1 - 1.5 * iqr), (q3 + 1.5 * iqr)\n",
    "        outlier_rate = float(((y < lower) | (y > upper)).mean())\n",
    "\n",
    "        target_summary = pd.DataFrame({\n",
    "            \"count\": [int(y.shape[0])],\n",
    "            \"mean\": [float(y.mean())],\n",
    "            \"median\": [float(y.median())],\n",
    "            \"std\": [float(y.std())],\n",
    "            \"min\": [float(y.min())],\n",
    "            \"p25\": [float(q1)],\n",
    "            \"p75\": [float(q3)],\n",
    "            \"max\": [float(y.max())],\n",
    "            \"skew\": [float(y.skew())],\n",
    "            \"iqr_outlier_rate\": [outlier_rate],\n",
    "        })\n",
    "        display(target_summary)\n",
    "\n",
    "        print(\n",
    "            f\"Interpretation: mean={target_summary.at[0,'mean']:.2f} vs. median={target_summary.at[0,'median']:.2f} | \"\n",
    "            f\"skew={target_summary.at[0,'skew']:.2f} | IQR-Ausrei√üerquote={outlier_rate:.1%}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Target enth√§lt keine Werte (nur NA) ‚Äì Kennzahlen werden √ºbersprungen.\")\n"
   ],
   "id": "c14eec695ff87a5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.6.4.1 Systematische Feature‚ÜíTarget-Beziehungen (numerisch)\n",
    "\n",
    "Statt nur einzelne Scatterplots zu zeigen, w√§hlen wir zus√§tzlich **die Top-n numerischen Features**\n",
    "mit der h√∂chsten absoluten Korrelation zum Preis (als schnelle Vorselektion) und plotten diese strukturiert.\n",
    "\n",
    "**Wichtig:** Korrelation ‚â† Kausalit√§t. Sie ist hier nur ein Screening-Tool f√ºr potenzielle Preistreiber.\n",
    "\"\"\"\n"
   ],
   "id": "eb1e19686ec867b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if target is not None and len(num_cols) >= 2:\n",
    "    corr_to_target = (\n",
    "        df[num_cols]\n",
    "        .corr(numeric_only=True)[target]\n",
    "        .drop(labels=[target], errors=\"ignore\")\n",
    "        .dropna()\n",
    "        .sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "    )\n",
    "\n",
    "    top_n_num = 3\n",
    "    top_num_features = corr_to_target.head(top_n_num).index.tolist()\n",
    "\n",
    "    print(\"Top numerische Features (nach |corr| mit Target):\", top_num_features)\n",
    "\n",
    "    for c in top_num_features:\n",
    "        plt.figure(figsize=(6.5, 5))\n",
    "        sns.scatterplot(data=df, x=c, y=target, alpha=0.3)\n",
    "        plt.title(f\"{target} vs. {c} (corr={corr_to_target.loc[c]:.2f})\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Kurze Interpretation: Wenn corr>0, steigt {target} tendenziell mit {c}; bei corr<0 tendenziell umgekehrt.\")\n",
    "else:\n",
    "    print(\"Top-n numerische Feature-Plots werden √ºbersprungen (target fehlt oder zu wenige numerische Spalten).\")\n"
   ],
   "id": "64cff09ef0d6c0ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Zwischenfazit:** Die st√§rksten linearen Zusammenh√§nge mit dem Verkaufspreis zeigen Wohnfl√§che, Gesamtqualit√§t und Lage. Grundst√ºcksgr√∂√üe und Baujahr weisen schw√§chere bzw. nichtlineare Effekte auf und sollten ggf. mit flexibleren Modellen betrachtet werden.",
   "id": "72bcab4251ec53a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.6.6.1 Korrelationen einordnen (Top-3 + Hinweis auf Multikollinearit√§t)\n",
    "\n",
    "Wir interpretieren die Korrelationsanalyse explizit:\n",
    "- **Top-3** Treiber nach absoluter Korrelation zum Ziel\n",
    "- Beispielhafter Check auf **Multikollinearit√§t** unter den Top-Features (stark korrelierte Pr√§diktoren)\n",
    "\n",
    "**Kurzfazit:**\n",
    "- Features mit hoher |corr| zum Target sind starke Kandidaten f√ºr die Modellierung.\n",
    "- Wenn zwei starke Treiber **untereinander** hoch korrelieren, sollte man f√ºr lineare Modelle Regularisierung nutzen oder eines der Features entfernen.\n",
    "\"\"\"\n"
   ],
   "id": "39283cbeef046c43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if target is not None and len(num_cols) >= 2:\n",
    "    corr = df[num_cols].corr(numeric_only=True)\n",
    "\n",
    "    if target in corr.columns:\n",
    "        corr_target = (\n",
    "            corr[target]\n",
    "            .drop(labels=[target], errors=\"ignore\")\n",
    "            .dropna()\n",
    "            .sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "        )\n",
    "\n",
    "        top3 = corr_target.head(3)\n",
    "        display(top3.to_frame(\"corr_with_target\"))\n",
    "\n",
    "        if len(top3) >= 2:\n",
    "            # Multikollinearit√§t: paarweise Korrelation zwischen Top-Features ansehen\n",
    "            top_feats = top3.index.tolist()\n",
    "            pair_corr = corr.loc[top_feats, top_feats]\n",
    "            display(pair_corr)\n",
    "else:\n",
    "    print(\"Korrelations-Interpretation wird √ºbersprungen.\")\n"
   ],
   "id": "7050779f7fa0a49d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Hinweis zur Interpretation der Korrelationen:** Das am st√§rksten korrelierte Feature zeigt den st√§rksten *linearen* Zusammenhang zum Target. Wenn die Top-Features untereinander stark korrelieren, kann das auf Multikollinearit√§t hinweisen; f√ºr lineare Modelle sind dann Regularisierung oder Feature-Selektion sinnvoll.",
   "id": "3a655561aa16ca6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.6.7.1 Systematische Feature‚ÜíTarget-Beziehungen (kategorial)\n",
    "\n",
    "Wir w√§hlen die **informativsten** kategorialen Features (heuristisch: moderate Kardinalit√§t) und zeigen\n",
    "jeweils die Preisverteilung per Boxplot.\n",
    "\n",
    "**Interpretation:** Kategorien mit klar getrennten Medianen sind starke Segmenttreiber.\n",
    "\"\"\"\n"
   ],
   "id": "182e7982922b8e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if target is not None:\n",
    "    # Heuristik: Kategorien mit 2..20 Auspr√§gungen (zu viele = un√ºbersichtlich, zu wenige = wenig Info)\n",
    "    candidate_cat = []\n",
    "    for c in cat_cols:\n",
    "        nunique_val = df[c].nunique(dropna=True)\n",
    "        try:\n",
    "            nunique = int(nunique_val)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if 2 <= nunique <= 20:\n",
    "            candidate_cat.append(c)\n",
    "\n",
    "    # maximal 3 Boxplots (\"weniger, aber sauber interpretiert\")\n",
    "    for c in candidate_cat[:3]:\n",
    "        vc = df[c].astype(\"string\").value_counts(dropna=False)\n",
    "        top_levels = vc.index[:min(TOP_K, len(vc))].tolist()\n",
    "        df_plot = df.loc[df[c].astype(\"string\").isin(top_levels), [c, target]].copy()\n",
    "        df_plot[c] = df_plot[c].astype(\"string\")\n",
    "\n",
    "        if df_plot.shape[0] >= 30:\n",
    "            plt.figure(figsize=(10, 4.5))\n",
    "            sns.boxplot(data=df_plot, y=c, x=target)\n",
    "            plt.title(f\"{target} nach {c} (Top-{min(TOP_K, len(top_levels))})\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            print(\n",
    "                f\"Kurze Interpretation: Wenn sich Median/Quartile zwischen Auspr√§gungen von '{c}' deutlich unterscheiden, \"\n",
    "                \"ist das Feature ein starker Kandidat f√ºr die Modellierung (Encoding n√∂tig).\"\n",
    "            )\n",
    "else:\n",
    "    print(\"Kategoriale Target-Beziehungen werden √ºbersprungen (target fehlt).\")\n"
   ],
   "id": "8f1bbd0bd99be85e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"### 2.5.1 Plausibilit√§ts-Logikchecks\n",
    "\n",
    "Neben reinen Negativ/Null-Checks sind einfache **Logikpr√ºfungen** wichtig.\n",
    "Typisch im Immobilienkontext:\n",
    "- Umbaujahr/Modernisierungsjahr sollte nicht vor Baujahr liegen.\n",
    "\n",
    "Diese Checks laufen nur, wenn entsprechende Spalten erkannt werden.\n",
    "\"\"\"\n"
   ],
   "id": "fcdacbd712c14e02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Heuristisch Spalten finden\n",
    "build_year_col = _find_numeric_col_by_keywords(df, [\"baujahr\", \"buildyear\", \"year_built\", \"built\"])\n",
    "renov_year_col = _find_numeric_col_by_keywords(df, [\"umbau\", \"modern\", \"sanier\", \"renov\", \"year_renov\", \"remodel\"])\n",
    "\n",
    "if build_year_col is not None:\n",
    "    by = df[build_year_col].dropna()\n",
    "    if len(by) > 0:\n",
    "        print(f\"Baujahr '{build_year_col}': min={int(by.min())}, max={int(by.max())}\")\n",
    "\n",
    "if build_year_col is not None and renov_year_col is not None:\n",
    "    mask = df[build_year_col].notna() & df[renov_year_col].notna()\n",
    "    inconsistent = int(np.count_nonzero((df.loc[mask, renov_year_col].to_numpy() < df.loc[mask, build_year_col].to_numpy())))\n",
    "    print(\n",
    "        f\"Logikcheck: Umbaujahr '{renov_year_col}' < Baujahr '{build_year_col}' ‚Üí \"\n",
    "        f\"{inconsistent} F√§lle (sollte i.d.R. 0 sein).\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Kein Baujahr/Umbaujahr-Paar gefunden ‚Äì Logikcheck wird √ºbersprungen.\")\n"
   ],
   "id": "da70f4599901fd82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üü¢ Neue finale Fassung (Copy-Paste-f√§hig)\n",
    "### 2.7 Zusammenfassung der wichtigsten Erkenntnisse aus der Data Exploration\n",
    "\n",
    "- **Zielvariable `Z_Verkaufspreis`:**\n",
    "  Der Verkaufspreis ist typischerweise rechtsschief verteilt und ausrei√üeranf√§llig.\n",
    "  F√ºr die Modellierung ist `log1p(Z_Verkaufspreis)` ein sinnvoller Kandidat.\n",
    "\n",
    "- **Wichtigste Preistreiber:**\n",
    "  Wohnfl√§che, Lage und Gesamtqualit√§t zeigen die st√§rksten Zusammenh√§nge\n",
    "  mit dem Verkaufspreis und sind zentrale Features f√ºr die Vorhersage.\n",
    "\n",
    "- **Numerische Features & Korrelationen:**\n",
    "  Die Top-3 numerischen Features nach |Korrelation| liefern eine sinnvolle erste\n",
    "  Priorisierung potenzieller Preistreiber.\n",
    "  Starke Feature-Feature-Korrelationen k√∂nnen lineare Modelle instabil machen.\n",
    "\n",
    "- **Kategoriale Features:**\n",
    "  Boxplots zeigen deutliche Preisunterschiede zwischen Kategorien\n",
    "  (z. B. Lage, Zustand, Qualit√§t), was deren hohe Relevanz best√§tigt.\n",
    "\n",
    "- **Konsequenzen f√ºr die Modellierung:**\n",
    "  Ausrei√üer erscheinen fachlich plausibel und werden nicht entfernt.\n",
    "  Es sind sowohl lineare als auch nichtlineare Zusammenh√§nge erkennbar,\n",
    "  weshalb mehrere Modelltypen sinnvoll erscheinen.\n",
    "\n",
    "### √úbergang zu Aufgabe 3 (Data Preparation)\n",
    "\n",
    "Aus der Exploration folgen konkret:\n",
    "- Umgang mit **Ausrei√üern** und ggf. **Target-Transformation** (`log1p`).\n",
    "- **Missing Values** je Feature gezielt behandeln (Imputation vs. Drop).\n",
    "- **Encoding** kategorialer Features (One-Hot/Ordinal) und B√ºndelung seltener Kategorien.\n",
    "- Optionales **Feature Engineering** (z.B. Geb√§udealter), falls passende Spalten vorhanden sind.\n",
    "\n",
    "---"
   ],
   "id": "5cbb72f12e6c2587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Data Preparation\n",
    "Ziel der Data Preparation ist es, auf Basis der Erkenntnisse aus der Data Exploration einen modellierbaren Datensatz zu erzeugen. Dabei werden fehlende Werte behandelt, Features transformiert und kategoriale Merkmale geeignet kodiert.\n"
   ],
   "id": "b0574970f003ac90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3.2 Zielvariable transformieren\n",
    "df[\"Z_Verkaufspreis_log\"] = np.log1p(df[\"Z_Verkaufspreis\"])"
   ],
   "id": "fdbedda3cbeac8e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "99afb01f8951df77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Da der Verkaufspreis rechtsschief verteilt ist und extreme Werte enth√§lt, wird f√ºr die\n",
    "Modellierung eine logarithmisch transformierte Darstellung der Zielvariable verwendet.\n",
    "Die Transformation reduziert die Schiefe der Verteilung und stabilisiert die Sch√§tzung\n",
    "der Regressionsmodelle, ohne die inhaltliche Bedeutung der Zielgr√∂√üe zu ver√§ndern."
   ],
   "id": "6e31eb90addef7d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3.3 ID entfernen\n",
    "df = df.drop(columns=[\"A_Index\"])"
   ],
   "id": "c0241bc7225938db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Spalte `A_Index` dient ausschlie√ülich der Identifikation der Datens√§tze und enth√§lt keine inhaltliche Information. Um Zufallskorrelationen und Overfitting zu vermeiden, wird dieses Merkmal vor der Modellierung entfernt.\n",
   "id": "de60efd33d79bb6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3.4 Feature Engineering: Geb√§udealter\n",
    "df[\"Gebaeudealter\"] = df[\"Verkaufsjahr\"] - df[\"Baujahr\"]\n",
    "df.loc[df[\"Gebaeudealter\"] < 0, \"Gebaeudealter\"] = np.nan"
   ],
   "id": "9da0ac7df0f38147"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Das Geb√§udealter ist f√ºr Investoren besser interpretierbar als das Baujahr und wird daher als zus√§tzliches Feature verwendet.\n",
    "Negative Geb√§udealter werden als unplausibel betrachtet und als fehlend behandelt.\n"
   ],
   "id": "2232f02dc9c40975"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3.5 Kategoriale Merkmale: Ordinal-Encoding\n",
    "ordinal_maps = {\n",
    "    \"Gesamtqual\": {\n",
    "        \"Sehr schlecht\": 1,\n",
    "        \"Schlecht\": 2,\n",
    "        \"Durchschnitt\": 3,\n",
    "        \"Gut\": 4,\n",
    "        \"Sehr gut\": 5\n",
    "    },\n",
    "    \"Gesamtzustand\": {\n",
    "        \"Sehr schlecht\": 1,\n",
    "        \"Schlecht\": 2,\n",
    "        \"Durchschnitt\": 3,\n",
    "        \"Gut\": 4,\n",
    "        \"Sehr gut\": 5\n",
    "    },\n",
    "    \"Kellerhoehe\": {\n",
    "        \"Keine Angabe\": 0,\n",
    "        \"Sehr schlecht\": 1,\n",
    "        \"Schlecht\": 2,\n",
    "        \"Durchschnitt\": 3,\n",
    "        \"Gut\": 4,\n",
    "        \"Sehr gut\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "for col, mapping in ordinal_maps.items():\n",
    "    # Missing/Unknown sauber auseinanderhalten: wir z√§hlen nur NaNs, die durch das Mapping neu entstehen.\n",
    "    s_raw = df[col]\n",
    "    na_before = int(s_raw.isna().sum())\n",
    "\n",
    "    df[col] = s_raw.map(mapping)\n",
    "\n",
    "    na_after = int(df[col].isna().sum())\n",
    "    introduced_by_map = na_after - na_before\n",
    "\n",
    "    if introduced_by_map > 0:\n",
    "        # Beispiele f√ºr unbekannte Kategorien (max. 10), damit man das Mapping gezielt erweitern kann.\n",
    "        unknown_examples = sorted(set(s_raw.dropna().astype(str)) - set(mapping.keys()))[:10]\n",
    "        print(\n",
    "            f\"Warnung: {introduced_by_map} unbekannte Auspr√§gungen in '{col}' \"\n",
    "            f\"(durch Mapping zu NaN). Beispiele: {unknown_examples}\"\n",
    "        )"
   ],
   "id": "163ec1ed0df8811e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ordinal skalierte Merkmale werden entsprechend ihrer nat√ºrlichen Rangfolge kodiert, um die enthaltene Ordnung f√ºr lineare Modelle nutzbar zu machen.\n",
    "Nach dem ordinalen Encoding wurde gepr√ºft, ob unbekannte Kategorien aufgetreten sind. Eventuell entstehende fehlende Werte werden im n√§chsten Schritt imputiert.\n",
    "\n"
   ],
   "id": "1c45f11eec9555a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3.6 Kategoriale Merkmale: One-Hot-Encoding\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=[\"Lage\", \"Ausbaustufe\", \"Steigung\", \"Besonderheiten\"],\n",
    "    drop_first=True\n",
    ")"
   ],
   "id": "3f013793bbdd4fc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nominale Merkmale ohne nat√ºrliche Ordnung werden mittels One-Hot-Encoding transformiert.\n",
    "F√ºr die sp√§tere Modellierung ist sicherzustellen, dass Trainings- und Testdaten dieselben Dummy-Spalten besitzen. Dies kann z. B. √ºber ein Alignment der Spalten oder den Einsatz von Pipelines erreicht werden.\n"
   ],
   "id": "4fa6bbc52b5a2fd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_cols = df.select_dtypes(include=[\"number\"]).columns.difference(\n",
    " [\"Z_Verkaufspreis\", \"Z_Verkaufspreis_log\"]\n",
    ")\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[num_cols] = imputer.fit_transform(df[num_cols])\n"
   ],
   "id": "20d8f505c6fcc3c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Fehlende Werte in numerischen Merkmalen werden mittels Median-Imputation ersetzt.\n",
    "Die Zielvariablen Z_Verkaufspreis und Z_Verkaufspreis_log werden nicht imputiert und\n",
    "explizit vom Feature Set ausgeschlossen."
   ],
   "id": "3bb4bd031d5b978e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fazit der Data Preparation\n",
    "Die Data Preparation umfasst die Transformation der Zielvariable in logarithmierter Form,\n",
    "die Entfernung irrelevanter Merkmale, die Erstellung neuer Features sowie die Kodierung\n",
    "und Imputation erkl√§render Merkmale. Die log-transformierte Zielvariable wird ausschlie√ülich\n",
    "als Regressionsziel verwendet und nicht als Feature in die Modelle eingebracht."
   ],
   "id": "161a578448177ac5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4 Modeling ‚Äì Regression mit Inferenz  ",
   "id": "b622689f7241195b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.1 Ziel und Vorgehen**  \n",
    "Ziel dieses Abschnitts ist die Vorhersage des Verkaufspreises einer Immobilie auf Basis ihrer objektbezogenen Merkmale.\n",
    "Hierzu werden mehrere Regressionsmodelle trainiert und anhand geeigneter G√ºtema√üe miteinander verglichen.\n",
    "Das Modell mit der besten Vorhersageleistung wird anschlie√üend f√ºr Prognosen auf den Testdaten verwendet.\n",
    "Der Fokus liegt dabei nicht nur auf der reinen Vorhersagequalit√§t, sondern auch auf der Interpretierbarkeit der preisbestimmenden Merkmale."
   ],
   "id": "6c6b3c4a1858cf44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.2 Zielvariable und Feature-Auswahl**\n",
    "\n",
    "Die Zielvariable der Regression ist der Verkaufspreis der Immobilie\n",
    "(Z_Verkaufspreis).\n",
    "\n",
    "Als erkl√§rende Variablen werden alle numerischen Objektmerkmale herangezogen,\n",
    "wobei die Zielvariable selbst sowie daraus abgeleitete Transformationen\n",
    "nicht Bestandteil des Feature-Sets sind.\n",
    "Auf diese Weise wird sichergestellt, dass die Vorhersage ausschlie√ülich auf\n",
    "objektbeschreibenden Merkmalen basiert und keine direkte Zielinformation\n",
    "in die Modellsch√§tzung einflie√üt."
   ],
   "id": "8863fe06256d81ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.3 Datenaufteilung in Trainings- und Validierungsdaten**  \n",
    "Um die Generalisierungsf√§higkeit der Modelle zu bewerten, werden die Daten in Trainings- und Validierungsdaten aufgeteilt.\n",
    "Die Validierungsdaten werden ausschlie√ülich zur Bewertung der Modelle verwendet."
   ],
   "id": "dc4f3a36c7429d1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Zielvariable\n",
    "y = df[\"Z_Verkaufspreis\"]\n",
    "\n",
    "# Features: alle numerischen Spalten au√üer Zielvariable\n",
    "X = df.select_dtypes(include=\"number\").drop(\n",
    "    columns=[\"Z_Verkaufspreis\", \"Z_Verkaufspreis_log\"]\n",
    ")\n",
    "\n",
    "# Aufteilung in Trainings- und Validierungsdaten\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Trainingsdaten:\", X_train.shape)\n",
    "print(\"Validierungsdaten:\", X_val.shape)"
   ],
   "id": "837aa8b235251002"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.4 Baseline Modell: Lineare Regression**  \n",
    "Als Basismodell wird eine lineare Regression verwendet.\n",
    "Dieses Modell dient als Referenz, da es einfach interpretierbar ist und h√§ufig als Ausgangspunkt f√ºr Regressionsaufgaben eingesetzt wird."
   ],
   "id": "3704c31494f22d13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lin_reg.predict(X_val)\n",
    "\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_val, y_pred_lr))\n",
    "r2_lr = r2_score(y_val, y_pred_lr)\n",
    "\n",
    "print(\"Lineare Regression\")\n",
    "print(\"RMSE:\", round(rmse_lr, 2))\n",
    "print(\"R¬≤:\", round(r2_lr, 3))"
   ],
   "id": "cdc36daca805318e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.5 Regularisiertes Modell: Ridge Regression**  \n",
    "Die Ridge Regression erweitert die lineare Regression um eine Regularisierung.\n",
    "Dadurch k√∂nnen instabile Koeffizienten reduziert und √úberanpassung vermieden werden, insbesondere bei korrelierten Merkmalen."
   ],
   "id": "f70786b6fe997774"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge = ridge.predict(X_val)\n",
    "\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_val, y_pred_ridge))\n",
    "r2_ridge = r2_score(y_val, y_pred_ridge)\n",
    "\n",
    "print(\"Ridge Regression\")\n",
    "print(\"RMSE:\", round(rmse_ridge, 2))\n",
    "print(\"R¬≤:\", round(r2_ridge, 3))"
   ],
   "id": "5139c110ed262738"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.6 Nichtlineares Modell: Random Forest Regression**\n",
    "Zur Modellierung nichtlinearer Zusammenh√§nge wird ein Random Forest Regressor eingesetzt.\n",
    "Dieses Modell kombiniert viele Entscheidungsb√§ume und ist in der Lage, komplexe Abh√§ngigkeiten zwischen Merkmalen abzubilden."
   ],
   "id": "252bfd6dbbcaa752"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_val, y_pred_rf))\n",
    "r2_rf = r2_score(y_val, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Regression\")\n",
    "print(\"RMSE:\", round(rmse_rf, 2))\n",
    "print(\"R¬≤:\", round(r2_rf, 3))"
   ],
   "id": "371804466d8fc450"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.7 Modellvergleich und Auswahl**\n",
    "Die Modelle werden anhand des Root Mean Squared Error (RMSE) sowie des Bestimmtheitsma√ües R¬≤ verglichen.\n",
    "Das Modell mit dem niedrigsten RMSE und der h√∂chsten erkl√§rten Varianz wird als bestes Modell ausgew√§hlt.\n",
    "In dieser Analyse zeigt der Random Forest Regressor die beste Vorhersageleistung und wird daher f√ºr weitere Prognosen verwendet."
   ],
   "id": "5d80d3b3cd64774c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.8 Interpretation der Einflussfaktoren**\n",
    "Zur Interpretation der Ergebnisse werden die Koeffizienten der linearen Regression sowie die Feature Importances des Random Forest betrachtet.\n",
    "Dies erm√∂glicht eine Einsch√§tzung, welche Merkmale den Verkaufspreis besonders stark beeinflussen."
   ],
   "id": "6a5a9b7adc872272"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Lineare Regression: Einfluss der Merkmale auf den Verkaufspreis**",
   "id": "1be6efa37751e544"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "coef_df = (\n",
    "    pd.DataFrame({\n",
    "        \"Merkmal\": X.columns,\n",
    "        \"Koeffizient\": lin_reg.coef_\n",
    "    })\n",
    "    .sort_values(by=\"Koeffizient\", key=abs, ascending=False)\n",
    ")\n",
    "\n",
    "coef_df.head(10)\n"
   ],
   "id": "3237b7d654ab05ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Random Forest: Relative Bedeutung der Merkmale f√ºr die Preisvorhersage**",
   "id": "f60c640d322ecab7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "importances = (\n",
    "    pd.Series(rf.feature_importances_, index=X.columns)\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "importances.head(10)"
   ],
   "id": "f4ee53c36cf0432b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.9 Einordnung von Varianz und Verzerrung**\n",
    "\n",
    "Die lineare Regression weist eine vergleichsweise hohe Verzerrung auf, da sie ausschlie√ülich lineare Zusammenh√§nge zwischen den Merkmalen und dem Verkaufspreis abbilden kann. Nichtlineare Effekte, insbesondere Interaktionen zwischen Lage, Qualit√§t und Wohnfl√§che, k√∂nnen nur eingeschr√§nkt erfasst werden. Dies zeigt sich in einer geringeren erkl√§rten Varianz im Vergleich zu komplexeren Modellen.\n",
    "\n",
    "Die Ridge-Regression reduziert zwar die Varianz der Sch√§tzung durch Regularisierung der Koeffizienten, f√ºhrt jedoch nicht zu einer signifikanten Verbesserung der Vorhersageg√ºte gegen√ºber der klassischen linearen Regression. Die zugrundeliegende Modellannahme bleibt weiterhin linear, sodass strukturelle Nichtlinearit√§ten unber√ºcksichtigt bleiben.\n",
    "\n",
    "Der Random Forest-Regressor weist im Vergleich dazu eine geringere Verzerrung auf, da er nichtlineare Zusammenh√§nge sowie Wechselwirkungen zwischen Merkmalen explizit modellieren kann. Durch die Aggregation vieler Entscheidungsb√§ume wird gleichzeitig die Varianz einzelner Modelle reduziert. Insgesamt ergibt sich damit ein g√ºnstigeres Bias-Variance-Verh√§ltnis."
   ],
   "id": "abf1ccfddd86ef7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.10 Vergleich der Regressionsmodelle**\n",
    "\n",
    "Der Vergleich der Modelle anhand von RMSE und R¬≤ zeigt, dass beide linearen Modelle eine √§hnliche Vorhersageleistung erzielen. Die Ridge-Regression bietet gegen√ºber der einfachen linearen Regression keinen deutlichen Vorteil, was darauf hindeutet, dass Multikollinearit√§t zwar vorhanden, aber nicht dominierend ist.\n",
    "\n",
    "Der Random Forest-Regressor erreicht hingegen den niedrigsten RMSE sowie das h√∂chste Bestimmtheitsma√ü. Dies spricht f√ºr eine bessere Anpassung an die Datenstruktur und eine h√∂here Prognoseg√ºte. Insbesondere die F√§higkeit, nichtlineare Effekte abzubilden, erweist sich bei der Immobilienpreisvorhersage als entscheidend."
   ],
   "id": "1df98c5d786f561d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.11 Interpretation der Einflussfaktoren im Modellvergleich**\n",
    "\n",
    "Die Koeffizienten der linearen Regression zeigen, dass insbesondere Gesamtqualit√§t, Kellerh√∂he, Verkaufsjahr und Wohnfl√§che einen positiven Einfluss auf den Verkaufspreis haben. Diese Effekte sind inhaltlich plausibel und gut interpretierbar, allerdings nur unter der Annahme linearer Zusammenh√§nge.\n",
    "\n",
    "Die Feature Importances des Random Forest best√§tigen diese Ergebnisse, priorisieren jedoch zus√§tzlich Wohnfl√§che und Gesamtqualit√§t als wichtigste Einflussfaktoren. Im Gegensatz zur linearen Regression ber√ºcksichtigt das Modell dabei auch nichtlineare Schwellen- und Interaktionseffekte, was die h√∂here Vorhersageleistung erkl√§rt."
   ],
   "id": "4213c164ffd89daa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.12 Modellfazit**\n",
    "\n",
    "Auf Basis der quantitativen G√ºtema√üe sowie der qualitativen Interpretation der Ergebnisse wird der Random Forest-Regressor als bestes Modell ausgew√§hlt. Er bietet die h√∂chste Prognosegenauigkeit bei gleichzeitig robuster Modellierung komplexer Zusammenh√§nge. Dieses Modell wird daher f√ºr die Vorhersage der Verkaufspreise auf den Testdaten verwendet."
   ],
   "id": "c6c31a7dbe714d96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.13 Modellanwendung und Vorhersage auf Testdaten**\n",
    "\n",
    "Auf Basis des Modellvergleichs wird der Random Forest-Regressor als finales Modell ausgew√§hlt.\n",
    "Um die bestm√∂gliche Prognosequalit√§t zu erzielen, wird dieses Modell abschlie√üend auf allen\n",
    "verf√ºgbaren Trainingsdaten neu trainiert.\n",
    "\n",
    "Das so refittete Modell wird anschlie√üend verwendet, um Verkaufspreisprognosen f√ºr die\n",
    "extern bereitgestellten Testdaten zu erzeugen. Die vorhergesagten Werte werden in eine neue\n",
    "Spalte der Datei *data_for_test.csv* geschrieben. Das urspr√ºngliche Datenformat sowie die\n",
    "Reihenfolge der Beobachtungen bleiben dabei unver√§ndert.miritest"
   ],
   "id": "674d956c1ee6d1a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Finale Feature- und Zieldefinition auf allen Trainingsdaten\n",
    "y_full = df[\"Z_Verkaufspreis\"]\n",
    "X_full = df.select_dtypes(include=\"number\").drop(\n",
    "    columns=[\"Z_Verkaufspreis\", \"Z_Verkaufspreis_log\"]\n",
    ")\n",
    "\n",
    "# Refit des finalen Modells auf allen Trainingsdaten\n",
    "final_model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "final_model.fit(X_full, y_full)\n",
    "\n",
    "# Laden der externen Testdaten\n",
    "df_test = pd.read_csv(\"data_for_test.csv\", sep=\";\")\n",
    "\n",
    "# Vorverarbeitung der Testdaten (analog zu Trainingsdaten)\n",
    "# ID entfernen\n",
    "df_test[\"Gebaeudealter\"] = df_test[\"Verkaufsjahr\"] - df_test[\"Baujahr\"]\n",
    "\n",
    "# Feature-Selektion f√ºr Testdaten (identisch zu Trainingsdaten)\n",
    "X_test = df_test[X_full.columns]\n",
    "\n",
    "# Vorhersage der Verkaufspreise\n",
    "df_test[\"Z_Verkaufspreis_Prediction\"] = final_model.predict(X_test)\n",
    "\n",
    "# Speicherung der Datei\n",
    "df_test.to_csv(\"data_for_test.csv\", index=False)\n"
   ],
   "id": "cd18e60fd700482f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
